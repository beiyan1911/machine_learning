{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "tensorflow 的保存和恢复功能十分方便，也十分强大。<br/>\n",
    "我们既可以保存/恢复变量，也可以保存/恢复整个模型。<br/>\n",
    "下面是几种保存/恢复的方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1、保存恢复变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved in path:/Users/beiyan/Documents/Projects/machine_learning/features/./tmp/save_restore_variable/model.ckpt \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "保存所有变量\n",
    "\"\"\"\n",
    "import tensorflow as tf\n",
    "from features import utils\n",
    "import os\n",
    "\n",
    "# 定义变量\n",
    "v1 = tf.get_variable('v1', shape=[3], initializer=tf.zeros_initializer)\n",
    "v2 = tf.get_variable('v2', shape=[5], initializer=tf.zeros_initializer)\n",
    "\n",
    "inc_v1 = v1.assign(v1 + 1)\n",
    "dec_v2 = v2.assign(v2 - 1)\n",
    "\n",
    "# 定义初始化操作\n",
    "init_op = tf.global_variables_initializer()\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # 初始化变量\n",
    "    sess.run(init_op)\n",
    "    # 计算\n",
    "    inc_v1.op.run()\n",
    "    dec_v2.op.run()\n",
    "    # 保存变量(此处文件夹需提前生成)\n",
    "    save_path = saver.save(sess, os.path.join(utils.localDir(), './tmp/save_restore_variable/model.ckpt'))\n",
    "    print(\"model saved in path:%s \" % save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /Users/beiyan/Documents/Projects/machine_learning/features/./tmp/save_restore_variable/model.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v1 :[1. 1. 1.] \nv2 :[-1. -1. -1. -1. -1.] \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "恢复所有变量\n",
    "\"\"\"\n",
    "tf.reset_default_graph()\n",
    "v1 = tf.get_variable(\"v1\", shape=[3])\n",
    "v2 = tf.get_variable(\"v2\", shape=[5])\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, os.path.join(utils.localDir(), './tmp/save_restore_variable/model.ckpt'))\n",
    "    print(\"v1 :%s \" % v1.eval())\n",
    "    print(\"v2 :%s \" % v2.eval())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /Users/beiyan/Documents/Projects/machine_learning/features/./tmp/save_restore_variable/model.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v1 : [0. 0. 0.]\nv2 : [-1. -1. -1. -1. -1.]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "恢复部分变量\n",
    "\"\"\"\n",
    "tf.reset_default_graph()\n",
    "v1 = tf.get_variable(\"v1\", [3], initializer=tf.zeros_initializer)\n",
    "v2 = tf.get_variable(\"v2\", [5], initializer=tf.zeros_initializer)\n",
    "# 只恢复v2 变量\n",
    "saver = tf.train.Saver({\"v2\": v2})\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    v1.initializer.run()\n",
    "    saver.restore(sess, os.path.join(utils.localDir(), \"./tmp/save_restore_variable/model.ckpt\"))\n",
    "    # v1 未恢复 v2恢复\n",
    "    print(\"v1 : %s\" % v1.eval())\n",
    "    print(\"v2 : %s\" % v2.eval())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----所有变量-----\ntensor_name:  v1\n[1. 1. 1.]\ntensor_name:  v2\n[-1. -1. -1. -1. -1.]\n-----v1-----\ntensor_name:  v1\n[1. 1. 1.]\n-----v2-----\ntensor_name:  v2\n[-1. -1. -1. -1. -1.]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "检查某个检查点中的变量\n",
    "\"\"\" \n",
    "from tensorflow.python.tools import inspect_checkpoint as chkp\n",
    "\n",
    "model_path = os.path.join(utils.localDir(), './tmp/save_restore_variable/model.ckpt')\n",
    "print(\"-----所有变量-----\")\n",
    "chkp.print_tensors_in_checkpoint_file(model_path, tensor_name='', all_tensors=True)\n",
    "print(\"-----v1-----\")\n",
    "chkp.print_tensors_in_checkpoint_file(model_path, tensor_name='v1', all_tensors=False)\n",
    "print(\"-----v2-----\")\n",
    "chkp.print_tensors_in_checkpoint_file(model_path, tensor_name='v2', all_tensors=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2、保存和恢复模型\n",
    "与只保存变量相比，保存模型更为有用。模型model包括--变量，图，图的元数据<br/>\n",
    "我们最希望的情况是：可以保存一个训练好的模型，下次直接读取这个训练好的模型进行预测<br/>\n",
    "tensorflow 提供 ***简单保存模型*** 以及 ***通过builder进行保存*** <br/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 简单保存模型\n",
    "简单保存主要是通过  tf.saved_model.simple_save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4.8252225]\n [10.825223 ]]\nINFO:tensorflow:Assets added to graph.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No assets to write.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:SavedModel written to: b'/Users/beiyan/Documents/Projects/machine_learning/features/./tmp/simple_save_restore/saved_model.pb'\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "保存模型\n",
    "\"\"\"\n",
    "import os\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "x = tf.placeholder(dtype=tf.float32, shape=[None, 2], name='input-x')\n",
    "w = tf.constant([[1], [2]], dtype=tf.float32)\n",
    "b = tf.get_variable('v1', [1], dtype=tf.float32, initializer=tf.random_normal_initializer)\n",
    "y = tf.add(tf.matmul(x, w), b,name='predit')\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    print(sess.run(y, feed_dict={x: [[1, 2], [3, 4]]}))\n",
    "\n",
    "    # 假设上面已经是训练好的模型了，此处进行保存\n",
    "    export_dir = os.path.join(utils.localDir(), './tmp/simple_save_restore/')\n",
    "    tf.saved_model.simple_save(sess,\n",
    "                               export_dir,\n",
    "                               inputs={\"x\": x},\n",
    "                               outputs={\"y\": y})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from b'/Users/beiyan/Documents/Projects/machine_learning/features/./tmp/simple_save_restore/variables/variables'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4.8252225]\n [10.825223 ]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "恢复应用模型\n",
    "\"\"\"\n",
    "# 注意 ；直接使用tf.python.saved_model.tag_constants.SERVING 会报错\n",
    "from tensorflow.python.saved_model import tag_constants\n",
    "\n",
    "tf.reset_default_graph()\n",
    "path = os.path.join(utils.localDir(), './tmp/simple_save_restore/')\n",
    "with tf.Session() as sess:\n",
    "    # SERVING = \"serve\"\n",
    "    # tf_export(\"saved_model.tag_constants.SERVING\").export_constant(\n",
    "    #     __name__, \"SERVING\")\n",
    "    tf.saved_model.loader.load(sess, [tag_constants.SERVING], path)\n",
    "    x = sess.graph.get_tensor_by_name('input-x:0')\n",
    "    y = sess.graph.get_tensor_by_name('predit:0')\n",
    "    print(sess.run(y, feed_dict={x: [[1, 2], [3, 4]]}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 手动构建SavedModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.294889 3.687993 4.652502]\nINFO:tensorflow:No assets to save.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No assets to write.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:SavedModel written to: b'/Users/beiyan/Documents/Projects/machine_learning/features/./tmp/builder_save_restore/saved_model.pb'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "b'/Users/beiyan/Documents/Projects/machine_learning/features/./tmp/builder_save_restore/saved_model.pb'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "保存模型\n",
    "\"\"\"\n",
    "tf.reset_default_graph()\n",
    "x = tf.placeholder(shape=[3], dtype=tf.float32, name='input-x')\n",
    "\n",
    "w = tf.get_variable('w', shape=[3], initializer=tf.random_uniform_initializer, dtype=tf.float32)\n",
    "z = tf.add(x, w, name='output-z')\n",
    "\n",
    "# builder\n",
    "export_dir = os.path.join(utils.localDir(), './tmp/builder_save_restore')\n",
    "builder = tf.saved_model.builder.SavedModelBuilder(export_dir)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    print(sess.run(z, feed_dict={x: [2, 3, 4]}))\n",
    "    #保存\n",
    "    builder.add_meta_graph_and_variables(sess,\n",
    "                                         ['saved_test'],\n",
    "                                         strip_default_attrs=True)\n",
    "builder.save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from b'/Users/beiyan/Documents/Projects/machine_learning/features/./tmp/builder_save_restore/variables/variables'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.294889 3.687993 4.652502]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "恢复应用模型\n",
    "\"\"\"\n",
    "tf.reset_default_graph()\n",
    "export_dir = os.path.join(utils.localDir(), './tmp/builder_save_restore')\n",
    "with tf.Session() as sess:\n",
    "    tf.saved_model.loader.load(sess, ['saved_test'], export_dir)\n",
    "    x = sess.graph.get_tensor_by_name('input-x:0')\n",
    "    z = sess.graph.get_tensor_by_name('output-z:0')\n",
    "    print(sess.run(z, feed_dict={x: [2, 3, 4]}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用SignatureDef 保存恢复模型\n",
    "以上两种保存恢复模型的方式都有一个问题，就是需要知道 输入节点 和 输出节点 在计算图中的名字<br/>\n",
    "如果使我们自己训练的模型，这样恢复也是可以的。但是如果使用别人训练好的模型，有时候我们是不知道节点的名字的。<br/>\n",
    "tensorflow 提供了SignatureDef，可以使我们更方便地定义模型中的输入输出<br/>\n",
    "可以理解为：SignatureDef定义了一些协议，对我们所需的信息进行封装，我们根据这套协议来获取信息，从而实现创建与使用模型的解耦。<br/>\n",
    "SignatureDef，将输入输出tensor的信息都进行了封装，并且给他们一个自定义的别名，所以在构建模型的阶段，可以随便给tensor命名，只要在保存训练好的模型的时候，在SignatureDef中给出统一的别名即可。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after step   0 ,the loss is 56239.167969\nafter step  20 ,the loss is 15322.833984\nafter step  40 ,the loss is 96.053955\nafter step  60 ,the loss is 16.751575\nafter step  80 ,the loss is 6.228118\nafter step 100 ,the loss is 2.361595\nafter step 120 ,the loss is 0.908338\nafter step 140 ,the loss is 0.354578\nafter step 160 ,the loss is 0.140375\nafter step 180 ,the loss is 0.056296\nINFO:tensorflow:No assets to save.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No assets to write.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:SavedModel written to: b'/Users/beiyan/Documents/Projects/machine_learning/features/./tmp/signature_save_restore/saved_model.pb'\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "保存模型\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "\n",
    "# 一个简单的两层全连接网络\n",
    "def inference(input_data):\n",
    "    w1 = tf.get_variable(name='w1', initializer=tf.truncated_normal(shape=[4, 3], stddev=0.01))\n",
    "    fc1 = tf.matmul(input_data, w1)\n",
    "    w2 = tf.get_variable(name='w2', initializer=tf.truncated_normal(shape=[3, 1], stddev=0.01))\n",
    "    return tf.matmul(fc1, w2)\n",
    "\n",
    "\n",
    "# 生成模拟测试数据\n",
    "def generateData():\n",
    "    x = np.ceil(np.random.rand(10, 4) * 10)\n",
    "    y = np.matmul(x, np.array([[1., 1., 1.], [2., 2., 2.], [3., 3., 3.], [4., 4., 4.]]))\n",
    "    y = np.matmul(y, np.array([[1.], [2.], [3.]]))\n",
    "    x = x.astype(np.float32)\n",
    "    y = y.astype(np.float32)\n",
    "    return x, y\n",
    "\n",
    "\n",
    "# 输入\n",
    "x = tf.placeholder(shape=[None, 4], dtype=tf.float32)\n",
    "y = tf.placeholder(shape=[None, 1], dtype=tf.float32)\n",
    "\n",
    "# 损失与优化\n",
    "logit = inference(x)\n",
    "loss = tf.losses.mean_squared_error(logit, y)\n",
    "optimize = tf.train.GradientDescentOptimizer(0.0001).minimize(loss)\n",
    "\n",
    "# 训练数据较少时可以使用tf.data 进行混排\n",
    "train_data, train_label = generateData()\n",
    "data = tf.data.Dataset.from_tensor_slices(train_data)\n",
    "label = tf.data.Dataset.from_tensor_slices(train_label)\n",
    "dataset = tf.data.Dataset.zip((data, label))\n",
    "dataset = dataset.repeat(100).batch(5)\n",
    "dataset_iterator = dataset.make_initializable_iterator()\n",
    "next_data, next_label = dataset_iterator.get_next()\n",
    "\n",
    "export_dir = os.path.join(utils.localDir(), './tmp/signature_save_restore')\n",
    "\n",
    "builder = tf.saved_model.builder.SavedModelBuilder(export_dir)\n",
    "inputs = {\"input-x\": tf.saved_model.utils.build_tensor_info(x)}\n",
    "outputs = {\"output\": tf.saved_model.utils.build_tensor_info(logit)}\n",
    "signature = tf.saved_model.signature_def_utils.build_signature_def(inputs=inputs, outputs=outputs,\n",
    "                                                                   method_name='test_sig_name')\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # 初始化变量\n",
    "    tf.global_variables_initializer().run()\n",
    "    # 初始化迭代器\n",
    "    sess.run(dataset_iterator.initializer)\n",
    "\n",
    "    for i in range(200):\n",
    "        batch_data, batch_label = sess.run([next_data, next_label])\n",
    "        _, l = sess.run([optimize, loss], feed_dict={x: batch_data, y: batch_label})\n",
    "        if i % 20 == 0:\n",
    "            print(\"after step %3d ,the loss is %.6f\" % (i, l))\n",
    "\n",
    "    builder.add_meta_graph_and_variables(sess, 'test_saved_model', {'test_signature': signature})\n",
    "    builder.save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from b'/Users/beiyan/Documents/Projects/machine_learning/features/./tmp/signature_save_restore/variables/variables'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[179.89954]\n [239.87839]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "恢复应用模型\n",
    "\"\"\"\n",
    "meta_graph_tag = 'test_saved_model'\n",
    "signature_key = 'test_signature'\n",
    "input_key = 'input-x'\n",
    "output_key = 'output'\n",
    "\n",
    "saved_dir = os.path.join(utils.localDir(), './tmp/signature_save_restore')\n",
    "with tf.Session() as sess:\n",
    "    meta_graph_def = tf.saved_model.loader.load(sess, meta_graph_tag, saved_dir)\n",
    "    signature = meta_graph_def.signature_def\n",
    "\n",
    "    x_tensor_name = signature[signature_key].inputs[input_key].name\n",
    "    y_tensor_name = signature[signature_key].outputs[output_key].name\n",
    "    x = sess.graph.get_tensor_by_name(x_tensor_name)\n",
    "    y = sess.graph.get_tensor_by_name(y_tensor_name)\n",
    "\n",
    "    y = sess.run(y, feed_dict={x: [[1, 2, 3, 4], [2, 3, 4, 5]]})\n",
    "    print(y)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
